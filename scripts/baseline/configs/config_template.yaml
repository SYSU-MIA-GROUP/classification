# Template train config file
experiments:
  name: "20210918_baseline"
  start_epoch: 1
  total_epochs: 200
  save_root: "~/Experiments/"
  tb_root: "~/Experiments/Tensorboard"
  log_fname: "train.log"
  save_period: 5
  eval_period: 1  # if 0, remove validate process when training.

train_transform:
  script_path: "common.transform.transform"
  name: "cifar_transform"
  param:
    phase: "train"
    resize: [32, 32]

eval_transform:
  script_path: "common.transform.transform"
  name: "cifar_transform"
  param:
    phase: "test"
    resize: [32, 32]

train_dataset:
  name: "ImbalanceCIFAR10"
  param:
    data_root: "~/Datasets/CIFAR10"
    train: True
    img_lst_fpath: "None"
    map_fpath: "None"
    imb_type: 'exp'
    imb_factor: 0.01
    rand_seed: 0
    download: True

eval_dataset:
  name: "ImbalanceCIFAR10"
  param:
    data_root: "~/Datasets/CIFAR10" # default: same as train_dataset
    train: False
    img_lst_fpath: "None"
    map_fpath: "None" # default: same as train_dataset
    download: False

trainloader:
  name: "Dataloader"
  param:
    sampler: "None"
    batch_size: 64
    num_workers: 8

evalloader:
  name: "Dataloader"
  param:
    batch_size: 64
    num_workers: 8

network:
  name: "ResNet32_CIFAR"
  param:
    num_classes: 10
    use_pretrained: False
    pretrained_fpath: ""
    resume_training: False
    resume_model_path: ""

loss:
  name: "CrossEntropyLoss"
  param: "none"

optimizer:
  name: "SGD"
  param:
    lr: 0.01
    weight_decay: 5.0e-5
    momentum: 1.0e-5
    use_nesterov: True

lr_scheduler:
  name: "CyclicLR"
  param:
    step_size_up: 3333  # 3 * iterations
    step_size_down: 2222  # 2 * iterations
    base_lr: 5.0e-6
    max_lr: 5.0e-3
