experiment:
  name: "ImageNet_CE_lr_0.2_5e-4"
  start_epoch: 1
  total_epochs: 90
  log_fname: "train.log"
  resume: False
  resume_fpath: "best.pth.tar"
  save_period: 10
  eval_period: 1  # if 0, remove validate process when training.

finetune:
  name: "DRW"
  total_epochs: 10
  unfreeze_keys: ["fc"]
  trainloader:
    sampler: ""
    retain_epoch_size: True
    batch_size: 256
    num_workers: 4
  network:
    name: ''
    param:
      in_channels: 512
      num_classes: 20
  loss:
    name: "CrossEntropyLoss"
    param:
      weight_type: "inverse"
      label_smoothing: 0.
  optimizer:
    name: "SGD"
    param:
      lr: 1.0e-1
      weight_decay: 1.0e-4
      momentum: 0.9
      nesterov: True
  lr_scheduler:
    name: 'StepLR'
    param:
      warmup_epochs: 0
      step_size: 3
      # milestones: [5, 10, 15, 20]
      gamma: 0.1

train_transform:
  name: "ImagenetTransform"
  param:
    phase: "train"
    resize: [224, 224]

val_transform:
  name: "ImagenetTransform"
  param:
    phase: "test"
    resize: [224, 224]

test_transform:
  name: "ImagenetTransform"
  param:
    phase: "test"
    resize: [224, 224]

head_class_idx:
  - 0
  - 390
med_class_idx:
  - 390
  - 835
tail_class_idx:
  - 835
  - 1000
  
train_dataset:
  name: "ImageNet_LT"
  param:
    phase: 'train'
    root: '/data16/Public/Datasets/ilsvrc2012'
    txt: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/ImageNet_LT_train.txt'
    map_fpath: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/map.npy'
    # train: True
    # img_lst_fpath: "None"
    # map_fpath: "None"
    imb_type: 'exp'

cutmix:
  beta: 1.
  prob: 1.

val_dataset:
  name: "ImageNet_LT"
  param:
    phase: 'val'
    root: '/data16/Public/Datasets/ilsvrc2012'
    txt: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/ImageNet_LT_val.txt'
    map_fpath: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/map.npy'
    # train: True
    # img_lst_fpath: "None"
    # map_fpath: "None"
    imb_type: 'exp'

test_dataset:
  name: "ImageNet_LT"
  param:
    phase: 'test'
    root: '/data16/Public/Datasets/ilsvrc2012'
    txt: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/ImageNet_LT_test.txt'
    map_fpath: '/home/19/chenghua/Projects/classification/data_loader/data/ImageNet_LT/map.npy'
    # train: True
    # img_lst_fpath: "None"
    # map_fpath: "None"
    imb_type: 'exp'


trainloader:
  sampler: 'DistributedSampler'
  batch_size: 512
  num_workers: 8

valloader:
  sampler: 'DistributedSampler'
  batch_size: 512
  num_workers: 8

testloader:
  sampler: 'DistributedSampler'
  batch_size: 128
  num_workers: 4

network:
  name: "ResNeXt50"
  param:
    pretrained: False
    pretrained_fpath: ""

loss:
  name: "CrossEntropyLoss"
  param:
    weight_type: ''
    label_smoothing: 0.

optimizer:
  name: "SGD"
  param:
    lr: 0.2
    weight_decay: 5.0e-4
    momentum: 0.9
    nesterov: True

lr_scheduler:
  # name: "CyclicLR"
  # name: "StepLR"
  # name: "MultiStepLR"
  # name: "CosineAnnealingWarmRestarts"
  name: "CosineAnnealingLR"
  param:
    warmup_epochs: 0
    # CyclicLR
    # step_size_up: 3  # 3 * iterations
    # step_size_down: 2  # 2 * iterations
    # max_lr: 5.0e-2
    # base_lr: 5.0e-7

    # MultiStepLR
    # milestones: [120, 160, 190]
    # gamma: 0.01

    # CosineAnnealingWarmRestarts
    # T_0: 0
    # T_mult: 1
    # eta_min: 0

    # CosineAnnealingLR
    T_max: 90
    eta_min: 0

test:
  name: "test"
  loss:
    name: "CrossEntropyLoss"
    param:
      weight_type: ""
      label_smoothing: 0.