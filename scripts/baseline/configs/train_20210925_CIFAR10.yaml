# Template train config/home/w/home/w/home/w/home/w/home/waaaaaafile
experiment:
  name: "20210925_CIFAR10"
  start_epoch: 1
  total_epochs: 200
  log_fname: "train.log"
  resume: False
  resume_fpath: ""
  save_period: 5
  eval_period: 1  # if 0, remove validate process when training.

train_transform:
  script_path: "data_loader.transform.transform"
  name: "cifar_transform"
  param:
    phase: "train"
    resize: [32, 32]

eval_transform:
  script_path: "data_loader.transform.transform"
  name: "cifar_transform"
  param:
    phase: "test"
    resize: [32, 32]

train_dataset:
  name: "CIFAR10"
  param:
    data_root: "CIFAR10"
    train: True
    img_lst_fpath: "None"
    map_fpath: "None"
    imb_type: 'exp'
    imb_factor: 0.01
    rand_seed: 0
    download: False

eval_dataset:
  name: "CIFAR10"
  param:
    data_root: "CIFAR10" # default: same as train_dataset
    train: False
    img_lst_fpath: "None"
    map_fpath: "None" # default: same as train_dataset
    download: False

trainloader:
  name: "Dataloader"
  param:
    sampler: None
    batch_size: 64
    num_workers: 8

evalloader:
  name: "Dataloader"
  param:
    batch_size: 64
    num_workers: 8

network:
  name: "ResNet32_CIFAR"
  param:
    num_classes: 10
    pretrained: False
    pretrained_fpath: ""

loss:
  name: "CrossEntropyLoss"
  param:
    a: 0.1

optimizer:
  name: "SGD"
  param:
    lr: 0.1
    weight_decay: 5.0e-5
    momentum: 1.0e-4
    nesterov: True

lr_scheduler:
  name: "CyclicLR"
  # name: "StepLR"
  param:
    # StepLR
    # step_size: 30
    # gamma: 0.1
    # CyclicLR
    step_size_up: 3  # 3 * iterations
    step_size_down: 2  # 2 * iterations
    base_lr: 1.0e-7
    max_lr: 5.0e-2
